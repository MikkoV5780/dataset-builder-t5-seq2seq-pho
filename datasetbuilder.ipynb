{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "import re\n",
    "from io import StringIO\n",
    "import time\n",
    "import os\n",
    "\n",
    "def setup_session():\n",
    "    \"\"\"Set up a requests session with retry functionality\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.25,\n",
    "        status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "def get_next_link(headers):\n",
    "    \"\"\"Extract next link from response headers for pagination\"\"\"\n",
    "    if \"Link\" in headers:\n",
    "        match = re.search(r'<(.+)>; rel=\"next\"', headers[\"Link\"])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_phosphorylated_proteins_mammals(session):\n",
    "    \"\"\"Fetch phosphorylated proteins data for mammals from UniProt\"\"\"\n",
    "    base_url = \"https://rest.uniprot.org/uniprotkb/search\"\n",
    "    \n",
    "    query_params = {\n",
    "        'query': 'taxonomy_id:40674 AND ft_mod_res:Phospho* AND reviewed:true',\n",
    "        'format': 'tsv',\n",
    "        'fields': 'accession,sequence,ft_mod_res',\n",
    "        'size': 500\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    url = base_url\n",
    "    \n",
    "    try:\n",
    "        while url:\n",
    "            response = session.get(url, params=query_params if url == base_url else None)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            total_results = int(response.headers.get(\"x-total-results\", 0))\n",
    "            \n",
    "            df = pd.read_csv(StringIO(response.text), sep='\\t')\n",
    "            results.append(df)\n",
    "            \n",
    "            print(f\"Retrieved {sum(len(df) for df in results)} of {total_results} records\")\n",
    "            \n",
    "            url = get_next_link(response.headers)\n",
    "            time.sleep(1)\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error occurred while fetching data: {e}\")\n",
    "        if results:\n",
    "            return pd.concat(results, ignore_index=True)\n",
    "        return None\n",
    "    \n",
    "    return pd.concat(results, ignore_index=True) if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phospho_positions_and_evidence(mod_res_string):\n",
    "    \"\"\"\n",
    "    Extract phosphorylation positions along with PubMed/UniProtKB identifiers\n",
    "    Returns sorted list of tuples (position, [evidence_ids])\n",
    "    \"\"\"\n",
    "    # Split string into individual modifications\n",
    "    mod_entries = re.split(r'(?=MOD_RES)', mod_res_string)\n",
    "    positions_with_evidence = []\n",
    "    \n",
    "    for entry in mod_entries:\n",
    "        entry = entry.strip()\n",
    "        if not entry.startswith('MOD_RES'):\n",
    "            continue\n",
    "        \n",
    "        # Extract position number\n",
    "        pos_match = re.search(r'MOD_RES\\s+(\\d+)', entry)\n",
    "        if not pos_match:\n",
    "            continue\n",
    "        \n",
    "        position = int(pos_match.group(1))\n",
    "        \n",
    "        # Check if it's a phosphorylation\n",
    "        if '/note=\"Phospho' not in entry:\n",
    "            continue\n",
    "        \n",
    "        # Extract evidence identifiers (PubMed or UniProtKB)\n",
    "        evidence_ids = []\n",
    "        \n",
    "        # Find all PubMed:XXXXX patterns\n",
    "        pubmed_matches = re.findall(r'PubMed:([0-9]+)', entry)\n",
    "        for pubmed_id in pubmed_matches:\n",
    "            evidence_ids.append(f\"PubMed:{pubmed_id}\")\n",
    "        \n",
    "        # Find all UniProtKB:XXXXX patterns\n",
    "        uniprotkb_matches = re.findall(r'UniProtKB:([A-Z0-9]+)', entry)\n",
    "        for uniprotkb_id in uniprotkb_matches:\n",
    "            evidence_ids.append(f\"UniProtKB:{uniprotkb_id}\")\n",
    "        \n",
    "        if evidence_ids:\n",
    "            positions_with_evidence.append((position, evidence_ids))\n",
    "    \n",
    "    return sorted(positions_with_evidence, key=lambda x: x[0])\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "    Process data into the desired format with additional column \n",
    "    containing phosphorylation identification sources\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Change column names\n",
    "    df.columns = ['ID', 'Sequence', 'MOD_RES']\n",
    "    \n",
    "    # Remove duplicates and rows with missing data\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Process each row\n",
    "    result_rows = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Extract phosphorylation positions and their sources\n",
    "        phospho_data = extract_phospho_positions_and_evidence(row['MOD_RES'])\n",
    "        \n",
    "        if phospho_data:  # Only if phosphorylation positions exist\n",
    "            # Create lists of positions and corresponding sources\n",
    "            positions = [str(pos) for pos, _ in phospho_data]\n",
    "            \n",
    "            # For each position, combine all sources into one value\n",
    "            evidence_sources = []\n",
    "            for _, sources in phospho_data:\n",
    "                if sources:\n",
    "                    # Take only the first identifier from the list for each position\n",
    "                    evidence_sources.append(sources[0])\n",
    "                else:\n",
    "                    evidence_sources.append('')\n",
    "            \n",
    "            result_rows.append({\n",
    "                'ID': row['ID'],\n",
    "                'Sequence': row['Sequence'],\n",
    "                'MOD_RES': ','.join(positions),\n",
    "                'MOD_RES_Accession': ','.join(evidence_sources)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    if result_rows:\n",
    "        result_df = pd.DataFrame(result_rows)\n",
    "        return result_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_phosphorylation_data(df):\n",
    "    \"\"\"Display statistics and sample data from processed phosphorylation dataset\"\"\"\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"Number of unique proteins: {len(df)}\")\n",
    "    \n",
    "    # Number of modifications per protein\n",
    "    df['MOD_Count'] = df['MOD_RES'].str.count(',') + 1\n",
    "    print(\"\\nStatistics of phosphorylation modifications per protein:\")\n",
    "    print(df['MOD_Count'].describe())\n",
    "    \n",
    "    # Example of first few proteins\n",
    "    print(\"\\nSample data (first 3 proteins):\")\n",
    "    sample_data = df[['ID', 'MOD_RES', 'MOD_RES_Accession']].head(3)\n",
    "    for _, row in sample_data.iterrows():\n",
    "        print(f\"ID: {row['ID']}\")\n",
    "        print(f\"Phosphorylation positions: {row['MOD_RES']}\")\n",
    "        print(f\"Identification sources: {row['MOD_RES_Accession']}\")\n",
    "        print()\n",
    "\n",
    "def split_proteins_by_evidence(input_file):\n",
    "    \"\"\"\n",
    "    Load CSV file with phosphorylated protein data and split each record\n",
    "    into multiple records according to evidence sources.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to CSV file containing data from previous analysis\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing split data\n",
    "    \"\"\"\n",
    "    # Load CSV file\n",
    "    print(f\"Loading file: {input_file}\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    print(f\"Number of records before splitting: {len(df)}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_columns = ['ID', 'Sequence', 'MOD_RES', 'MOD_RES_Accession']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    # List to store new records\n",
    "    new_records = []\n",
    "    \n",
    "    # Process each row\n",
    "    for _, row in df.iterrows():\n",
    "        id_val = row['ID']\n",
    "        sequence = row['Sequence']\n",
    "        mod_positions = row['MOD_RES'].split(',')\n",
    "        mod_accessions = row['MOD_RES_Accession'].split(',')\n",
    "        \n",
    "        # Check if number of positions and accessions is the same\n",
    "        if len(mod_positions) != len(mod_accessions):\n",
    "            print(f\"WARNING: Mismatch in number of positions and accessions for ID: {id_val}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Group positions by evidence\n",
    "        evidence_to_positions = {}\n",
    "        \n",
    "        for pos, acc in zip(mod_positions, mod_accessions):\n",
    "            # Extract main evidence identifier (before first comma, if there are more)\n",
    "            main_evidence = acc.split(',')[0].strip()\n",
    "            \n",
    "            if not main_evidence:\n",
    "                continue\n",
    "                \n",
    "            if main_evidence not in evidence_to_positions:\n",
    "                evidence_to_positions[main_evidence] = []\n",
    "            \n",
    "            evidence_to_positions[main_evidence].append(pos)\n",
    "        \n",
    "        # Create new record for each unique evidence\n",
    "        for evidence, positions in evidence_to_positions.items():\n",
    "            new_records.append({\n",
    "                'ID': id_val,\n",
    "                'Sequence': sequence,\n",
    "                'MOD_RES': ','.join(positions),\n",
    "                'MOD_RES_Accession': evidence,\n",
    "                'Position_Count': len(positions)\n",
    "            })\n",
    "    \n",
    "    # Create new DataFrame with split data\n",
    "    result_df = pd.DataFrame(new_records)\n",
    "    \n",
    "    print(f\"Number of records after splitting: {len(result_df)}\")\n",
    "    \n",
    "    # Sort by ID and number of positions (descending)\n",
    "    result_df = result_df.sort_values(['ID', 'Position_Count'], ascending=[True, False])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_sequence_at_positions(row):\n",
    "    \"\"\"\n",
    "    Modify sequence by converting characters to lowercase at given positions.\n",
    "    Positions in MOD_RES are numbered from 1, so we need to subtract 1 for indices.\n",
    "    \"\"\"\n",
    "    sequence = list(row['Sequence'])\n",
    "    # Convert position string to list of numbers (only if positions are non-empty)\n",
    "    if pd.notna(row['MOD_RES']) and row['MOD_RES'].strip():\n",
    "        positions = [int(pos) for pos in row['MOD_RES'].split(',')]\n",
    "        \n",
    "        # Change characters to lowercase at given positions (subtract 1 to adjust to 0-indexing)\n",
    "        for pos in positions:\n",
    "            idx = pos - 1  # convert position to index\n",
    "            if 0 <= idx < len(sequence):  # check if index is valid\n",
    "                sequence[idx] = sequence[idx].lower()\n",
    "    \n",
    "    return ''.join(sequence)\n",
    "\n",
    "def process_modified_sequences(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process the input file to create modified sequences with lowercase at phosphorylation sites\n",
    "    and save to output file\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"ERROR: File {input_file} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load file\n",
    "        print(f\"Loading file: {input_file}\")\n",
    "        split_df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Add new column with modified sequences\n",
    "        print(\"Creating modified sequences...\")\n",
    "        split_df['Modified_Sequence'] = split_df.apply(modify_sequence_at_positions, axis=1)\n",
    "        \n",
    "        # Save result to CSV file\n",
    "        split_df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to file: {output_file}\")\n",
    "        \n",
    "        # Display basic information\n",
    "        print(f\"\\nNumber of records: {len(split_df)}\")\n",
    "        print(f\"Number of unique proteins: {split_df['ID'].nunique()}\")\n",
    "        \n",
    "        # Examples for several different proteins\n",
    "        print(\"\\nExamples of modified sequences:\")\n",
    "        sample_ids = split_df['ID'].drop_duplicates().head(3)\n",
    "        sample_data = split_df[split_df['ID'].isin(sample_ids)].groupby('ID').head(1)\n",
    "        \n",
    "        for _, row in sample_data.iterrows():\n",
    "            print(f\"ID: {row['ID']}\")\n",
    "            print(f\"Identification source: {row['MOD_RES_Accession']}\")\n",
    "            print(f\"Phosphorylation positions: {row['MOD_RES']}\")\n",
    "            \n",
    "            # Display fragment of sequence around phosphorylation sites\n",
    "            mod_positions = [int(pos) for pos in row['MOD_RES'].split(',')]\n",
    "            if mod_positions:\n",
    "                # Find first phosphorylation position\n",
    "                pos = mod_positions[0]\n",
    "                start = max(0, pos - 10)\n",
    "                end = min(len(row['Sequence']), pos + 10)\n",
    "                \n",
    "                original_fragment = row['Sequence'][start:end]\n",
    "                modified_fragment = row['Modified_Sequence'][start:end]\n",
    "                \n",
    "                print(f\"Original sequence fragment: ...{original_fragment}...\")\n",
    "                print(f\"Modified sequence fragment: ...{modified_fragment}...\")\n",
    "            print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fetch_data():\n",
    "    \"\"\"Main function to fetch and process initial phosphorylation data\"\"\"\n",
    "    print(\"Starting download of phosphorylated protein data for mammals...\")\n",
    "    \n",
    "    session = setup_session()\n",
    "    raw_df = get_phosphorylated_proteins_mammals(session)\n",
    "    \n",
    "    if raw_df is not None:\n",
    "        processed_df = process_data(raw_df)\n",
    "        \n",
    "        if processed_df is not None:\n",
    "            output_file = \"phosphorylated_proteins_mammals_clean.csv\"\n",
    "            processed_df.to_csv(output_file, index=False)\n",
    "            print(f\"\\nData saved to file: {output_file}\")\n",
    "            \n",
    "            analyze_phosphorylation_data(processed_df)\n",
    "    else:\n",
    "        print(\"Failed to fetch data.\")\n",
    "\n",
    "def main_split_by_evidence():\n",
    "    \"\"\"Main function to split proteins by evidence sources\"\"\"\n",
    "    # Path to input file\n",
    "    input_file = \"phosphorylated_proteins_mammals_clean.csv\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"ERROR: File {input_file} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Split data by evidence\n",
    "        split_df = split_proteins_by_evidence(input_file)\n",
    "        \n",
    "        # Path to output file\n",
    "        output_file = \"phosphorylated_proteins_mammals_split_by_evidence.csv\"\n",
    "        \n",
    "        # Save result to CSV file\n",
    "        split_df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to file: {output_file}\")\n",
    "        \n",
    "        # Display statistics\n",
    "        print(\"\\nStatistics:\")\n",
    "        print(f\"Number of unique proteins: {split_df['ID'].nunique()}\")\n",
    "        print(f\"Number of all evidence variants: {len(split_df)}\")\n",
    "        print(\"\\nNumber of phosphorylation sites per evidence variant:\")\n",
    "        print(split_df['Position_Count'].describe())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during data processing: {e}\")\n",
    "\n",
    "def main_create_modified_sequences():\n",
    "    \"\"\"Main function to create modified sequences\"\"\"\n",
    "    # Path to input file with evidence variants\n",
    "    input_file = \"phosphorylated_proteins_mammals_split_by_evidence.csv\"\n",
    "    output_file = \"phosphorylated_proteins_with_modified_sequences.csv\"\n",
    "    \n",
    "    process_modified_sequences(input_file, output_file)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution flow\"\"\"\n",
    "    # Uncomment the function you want to run\n",
    "    main_fetch_data()\n",
    "    main_split_by_evidence()\n",
    "    main_create_modified_sequences()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
